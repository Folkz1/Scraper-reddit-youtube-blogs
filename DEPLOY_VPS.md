# üöÄ Deploy na VPS

Guia completo para fazer deploy do microservi√ßo de scraper na sua VPS.

## üìã Pr√©-requisitos

- VPS com Ubuntu/Debian
- Docker e Docker Compose instalados
- Porta 8001 dispon√≠vel

## üîß Instala√ß√£o do Docker (se necess√°rio)

```bash
# Atualizar sistema
sudo apt update && sudo apt upgrade -y

# Instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Instalar Docker Compose
sudo apt install docker-compose -y

# Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

## üì¶ Deploy com Docker Compose (Recomendado)

### 1. Clonar/Enviar c√≥digo para VPS

```bash
# Op√ß√£o 1: Via Git
git clone seu-repositorio
cd microservico_scraper

# Op√ß√£o 2: Via SCP (do seu PC)
scp -r microservico_scraper usuario@seu-vps:/home/usuario/
```

### 2. Configurar vari√°veis de ambiente (opcional)

```bash
# Copiar exemplo
cp .env.example .env

# Editar com suas credenciais Reddit (opcional)
nano .env
```

### 3. Build e Run

```bash
# Build da imagem
docker-compose build

# Rodar em background
docker-compose up -d

# Ver logs
docker-compose logs -f
```

### 4. Testar

```bash
# Health check
curl http://localhost:8001/health

# Teste de scraping
curl -X POST http://localhost:8001/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://wellworthy.com/monster-enters-the-female-focused-energy-game-with-flrt/"}'
```

## üê≥ Deploy com Docker (Manual)

```bash
# Build
docker build -t scraper-api .

# Run
docker run -d \
  --name scraper-api \
  -p 8001:8001 \
  --restart unless-stopped \
  scraper-api

# Ver logs
docker logs -f scraper-api
```

## üîÑ Atualizar o servi√ßo

```bash
# Parar containers
docker-compose down

# Atualizar c√≥digo (git pull ou scp)
git pull

# Rebuild e restart
docker-compose up -d --build
```

## üåê Expor para internet

### Op√ß√£o 1: Nginx Reverse Proxy

```nginx
# /etc/nginx/sites-available/scraper-api
server {
    listen 80;
    server_name scraper.seudominio.com;

    location / {
        proxy_pass http://localhost:8001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

```bash
# Ativar site
sudo ln -s /etc/nginx/sites-available/scraper-api /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx

# SSL com Certbot (opcional)
sudo apt install certbot python3-certbot-nginx -y
sudo certbot --nginx -d scraper.seudominio.com
```

### Op√ß√£o 2: Expor porta diretamente

```bash
# Abrir porta no firewall
sudo ufw allow 8001/tcp
```

## üìä Monitoramento

### Ver status

```bash
docker-compose ps
```

### Ver logs

```bash
# √öltimas 100 linhas
docker-compose logs --tail=100

# Seguir logs em tempo real
docker-compose logs -f

# Logs de um servi√ßo espec√≠fico
docker-compose logs -f scraper-api
```

### Reiniciar servi√ßo

```bash
docker-compose restart
```

## üîß Troubleshooting

### Container n√£o inicia

```bash
# Ver logs de erro
docker-compose logs

# Verificar se porta est√° em uso
sudo netstat -tulpn | grep 8001

# Rebuild for√ßado
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### Erro de mem√≥ria

```bash
# Limpar containers antigos
docker system prune -a

# Verificar uso de recursos
docker stats
```

### YouTube n√£o funciona

O YouTube pode bloquear IPs de VPS. Solu√ß√µes:
1. Usar proxy/VPN
2. Rotacionar IPs
3. Adicionar delays entre requests

## üîê Seguran√ßa

### Limitar acesso por IP

```nginx
# No Nginx
location / {
    allow 192.168.1.0/24;  # Sua rede
    deny all;
    proxy_pass http://localhost:8001;
}
```

### Adicionar autentica√ß√£o

```nginx
# Criar arquivo de senha
sudo apt install apache2-utils
sudo htpasswd -c /etc/nginx/.htpasswd usuario

# No Nginx
location / {
    auth_basic "Restricted";
    auth_basic_user_file /etc/nginx/.htpasswd;
    proxy_pass http://localhost:8001;
}
```

## üìà Performance

### Aumentar workers

Edite `app.py`:

```python
if __name__ == "__main__":
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8001,
        workers=4  # Adicione esta linha
    )
```

### Limitar recursos do Docker

```yaml
# docker-compose.yml
services:
  scraper-api:
    # ...
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 512M
```

## üîÑ Auto-restart

O Docker Compose j√° est√° configurado com `restart: unless-stopped`.

Para garantir que inicie no boot:

```bash
# Habilitar Docker no boot
sudo systemctl enable docker

# Criar servi√ßo systemd (opcional)
sudo nano /etc/systemd/system/scraper-api.service
```

```ini
[Unit]
Description=Scraper API
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/usuario/microservico_scraper
ExecStart=/usr/bin/docker-compose up -d
ExecStop=/usr/bin/docker-compose down
TimeoutStartSec=0

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl enable scraper-api
sudo systemctl start scraper-api
```

## üìû Uso no n8n

No seu workflow n8n, use o HTTP Request node:

```json
{
  "method": "POST",
  "url": "http://seu-vps:8001/scrape",
  "body": {
    "url": "{{ $json.article_url }}",
    "type": "auto"
  }
}
```

Resposta:
```json
{
  "success": true,
  "type": "article",
  "data": {
    "title": "...",
    "content": "...",
    "word_count": 1500
  }
}
```

## ‚úÖ Checklist de Deploy

- [ ] Docker e Docker Compose instalados
- [ ] C√≥digo copiado para VPS
- [ ] `.env` configurado (se usar Reddit)
- [ ] `docker-compose up -d` executado
- [ ] Health check funcionando
- [ ] Teste de scraping OK
- [ ] Firewall configurado
- [ ] Nginx configurado (se usar)
- [ ] SSL configurado (se usar)
- [ ] Auto-restart habilitado

## üéâ Pronto!

Seu microservi√ßo est√° rodando em: `http://seu-vps:8001`

Documenta√ß√£o interativa: `http://seu-vps:8001/docs`
